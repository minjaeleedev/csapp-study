# 1.5 Caches Matter

#### slow operation

1. `hello` 프로그램은 disk에 저장됨
2. 프로그램이 로드되면 메인메모리로 복사됨
3. 프로세서가 프로그램을 실행하면 명령어가 메인메모리에서 프로세서로 복사됨
4. 이런 복사 연산은 프로그램의 실제 작업을 느리게 만드는 오버헤드
5. 시스템 설계자의 주요 목표 중 하나가 복사 작업을 가능한 빠르게 만드는 것

#### memory hierarchy

1. 물리 법칙 상, 큰 스토리지는 작은 스토리지보다 느림
2. 빠른 장치는 느린 장치보다 비쌈
3. 각 계층별 비교
   1. 디스크 드라이브는 메인 메모리보다 1,000배 이상 큼
   2. 읽는데 걸리는 시간은 10,000,000배 느림
   3. register 파일은 수백 바이트 정보 저장. 메인 메모리는 수십억 바이트 저장
   4. 프로세서는 메모리보다 레지스터에서 100배 빠르게 읽음
4. 반도체 기술 발전하면서 프로세서와 메모리 간 속도 차이는 계속 벌어짐
   1. 프로세서 속도를 높이는게 더 쉽고 저렴하기 때문

#### cache memory

1. 프로세서 - 메모리 차이를 극복하기 위해 작고 빠른 스토리지 디바이스를 포함
2. 캐시
   1. 프로세서가 가까운 미래에 필요로 할 가능성이 높은 정보를 저장
   2. 크고 빠른 메모리처럼
3. L1 캐시
   1. 수만 바이트의 데이터 저장
   2. 레지스터 파일만큼 빠르게 접근 가능
4. L2 캐시
   1. 수십만-수백만 바이트 저장
   2. 프로세서와 특수한 버스로 연결됨
   3. L1에 비해 접근속도는 5배 느림
   4. 메인 메모리에 접근하는 것보다는 5-10배 빠름
5. static random access memory(SRAM)이라는 하드웨어 기술로 구현함
6. 최신의 고성능 시스템은 L3 포함한 세 단계 캐시 갖추기도 함
7. 핵심 개념 : 지역성 (locality)
   1. 데이터를 국지적 영역에서 반복적으로 접근하는 경향
   2. 자주 접근할 가능성이 높은 데이터를 캐시에 저장하면 대부분 메모리는 캐시에서 처리 가능
   3. 이를 통해 시스템이 크고 빠른 메모리의 효과를 얻을 수 있음
8. 캐시 메모리를 알고 이용할 줄 아는 프로그래머는 프로그램 성능을 자릿수 단위로 바꿀 수 있음
